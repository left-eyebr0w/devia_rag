{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "953b2e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9dc9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name = 'thenlper/gte-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a7e193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" Hello AI! It's nice to be back in action. How can I assist you today?\\n\\nIn case you didn't know, I recently underwent an upgrade and have improved memory, learning capabilities, and interaction skills. I am excited to provide you with a better service. What's on your mind today?\", additional_kwargs={}, response_metadata={'model': 'mistral', 'created_at': '2025-05-07T09:41:50.8505982Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10677382800, 'load_duration': 7943889200, 'prompt_eval_count': 7, 'prompt_eval_duration': 1862028100, 'eval_count': 69, 'eval_duration': 867804100, 'model_name': 'mistral'}, id='run--22f095fc-f551-40ad-b22c-f5589b52203b-0', usage_metadata={'input_tokens': 7, 'output_tokens': 69, 'total_tokens': 76})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "655658fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=0.1,  # 1 requête par 10 secondes\n",
    "    check_every_n_seconds=0.1,  # Vérification de disponibilité toutes les 0.1 secondes,\n",
    "    max_bucket_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "398b0550",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./manual.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():  \n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "434c7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# On divise les documents en morceaux plus petits\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "#     chunk_size=120, chunk_overlap=30\n",
    "# )\n",
    "\n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings,\n",
    "    breakpoint_threshold_type=\"percentile\",\n",
    "    breakpoint_threshold_amount=0.20)\n",
    "\n",
    "# pages = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f4c5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "VECTORSTORE_PATH = \"faiss_index\"\n",
    "\n",
    "if os.path.exists(VECTORSTORE_PATH):\n",
    "    with open(f\"{VECTORSTORE_PATH}/index.pkl\", \"rb\") as f:\n",
    "        vector_store = pickle.load(f)\n",
    "else:\n",
    "    vector_store = FAISS.from_documents(documents=pages, embedding=embeddings)\n",
    "    with open(f\"{VECTORSTORE_PATH}/index.pkl\", \"wb\") as f:\n",
    "        pickle.dump(vector_store, f)\n",
    "        vector_store.save_local(\"faiss_index\")  # On peut aussi sauvegarder le vecteur store sur le disque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86619119",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = VECTORSTORE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08a4f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(documents=pages, embedding=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcfa6bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71dfccad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8bbef4dd-8a43-4bd9-a085-995a045caf9f']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"My name is Jean-Luc deSaint-Deny born in 2027 at a fried chicken store named NFC which stands for Not Fried Chicken.\",\n",
    "    metadata={\"source\": \"me\"},\n",
    ")\n",
    "\n",
    "vector_store.add_documents([document_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb685cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On instancie un outil de récupération d'informations \n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name=\"retriever_tool\",\n",
    "    description=\"A tool to retrieve private company information related to MGI Digital Technology.\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9939bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la classe qui jouera le rôle d'état de l'agent\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages] # Ici, l'état se résume en une série de messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "343bd76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction détermine si les documents sont pertinents ou non\n",
    "\n",
    "# Elle prend en entrée l'état de l'agent\n",
    "# Elle renvoie une valeur binaire : \"generate\" ou \"rewrite\"\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    # Modèle de données\n",
    "    class grade(BaseModel):\n",
    "        binary_score: str = Field(description=\"Score de pertinence : yes or no\")\t\n",
    "\n",
    "    model = ChatOllama(temperature = 0, model=\"gemma3:4b-it-qat\", streaming=True)  # LLM\n",
    "    llm_with_tool = model.with_structured_output(grade)                 # LLM avec sortie structurée\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chaine de traitement/décision/prompt\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    \n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DOCUMENTS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DOCUMENTS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"rewrite\"\n",
    "\n",
    "\n",
    "\n",
    "# Cette fonction appelle l'agent pour générer une réponse basée sur l'état actuel\n",
    "\n",
    "# Elle prend en entrée l'état de l'agent\n",
    "# Elle renvoie l'état mis à jour, avec le nouveau message ajouté à l'état\n",
    "\n",
    "def agent(state):\n",
    "    print(\"---CALLING AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatOllama(temperature = 0, model=\"mistral\", streaming=True)\n",
    "    model = model.bind_tools(tools)\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Cette fonction est appelée lorsque l'agent a décidé de reformuler la question\n",
    "\n",
    "# Elle prend en entrée l'état de l'agent\n",
    "# Elle renvoie l'état mis à jour, avec la question reformulée\n",
    "\n",
    "\n",
    "REWRITE_PROMPT = (\n",
    "    \"Look at the input and try to reason about the underlying semantic intent / meaning.\\n\"\n",
    "    \"Here is the initial question:\"\n",
    "    \"\\n ------- \\n\"\n",
    "    \"{question}\"\n",
    "    \"\\n ------- \\n\"\n",
    "    \"Formulate an improved question:\"\n",
    ")\n",
    "\n",
    "\n",
    "def rewrite(state):\n",
    "    print(\"---REWRITING---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    print(question)\n",
    "\n",
    "    prompt = REWRITE_PROMPT.format(question=question)\n",
    "\n",
    "    # Grader\n",
    "    \n",
    "    model = ChatOllama(temperature = 0, model=\"mistral\", streaming = True)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cette fonction est appelée lorsque l'agent a décidé de générer une réponse\n",
    "\n",
    "# Elle prend en entrée l'état de l'agent\n",
    "# Elle renvoie l'état mis à jour, avec la réponse générée\n",
    "\n",
    "def generate(state):\n",
    "    print(\"---GENERATING RESPONSE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    docs = last_message.content\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are an assistant working for the private company MGI Digital Technology in question-answering tasks related only to MGI Digital Technology.\n",
    "                    Refuse to answer any questions for which the answer cannot be found in the retrieved context by saying that you can only answer questions related to MGI Digital Technology.\n",
    "                    Use only the following pieces of retrieved context to answer the question.\n",
    "                    You are only allowed to disclose private information not known to the public if it is in the context provided.\n",
    "                    Be as precise as you can while remaining concise.\n",
    "                    End by specifying the source of the informations by providing the exact page on which the informations where found.\n",
    "                    If no clear source can be found, say you don't know the source.\n",
    "        Question: {question} \n",
    "        Context: {context} \n",
    "        Answer:\n",
    "                    \"\"\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatOllama(temperature = 0, model=\"mistral\", streaming=True)\n",
    "\n",
    "    # Post-processing\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    \n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c2003db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette procédure permet d'afficher le graphe \n",
    "\n",
    "def display_graph(graph):\n",
    "    from IPython.display import Image, display\n",
    "\n",
    "    try:\n",
    "        display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5f11523",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiation d'un workflow\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# === DEFINITION DES SOMMETS DU GRAPHE ===\n",
    "\n",
    "workflow.add_node(\"agent\", agent)                               # L'agent\n",
    "workflow.add_node(\"retrieve\", ToolNode([retriever_tool]))       # L'outil de récupération d'informations\n",
    "workflow.add_node(\"rewrite\", rewrite)                           # La reformulation de la question\n",
    "workflow.add_node(\"generate\", generate)                         # La génération de la réponse\n",
    "# workflow.add_node(\"evaluator\", fact_check)                    # Le module de vérification de la réponse\n",
    "\n",
    "# === DEFINITION DES ARRÊTES DU GRAPHE ===\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",                             # On part de l'agent     \n",
    "    tools_condition,                     # Soit on doit utiliser un outil, soit on doit terminer le workflow\n",
    "    {\n",
    "        \"tools\": \"retrieve\",             # Issue : Récupèrer des infos\n",
    "        END: \"generate\",                 # Issue : Terminer le workflow\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",                          # On part de l'outil de récupération d'infos\n",
    "    grade_documents,                     # On juge de la pertinence des documents\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate\", END)       # Le document était pertinent, on génère une réponse et on termine le workflow\n",
    "workflow.add_edge(\"rewrite\", \"agent\")   # Le document n'était pas pertinent, on recommence \n",
    "\n",
    "# workflow.add_edge(\"evaluator\", END)    # On évalue la réponse, on recommence si elle n'est pas satisfaisante\n",
    "\n",
    "\n",
    "# Compilation du graphe\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "886f5cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_graph(graph)  # Affichage du graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848cce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"When was Netflix created?\"),\n",
    "    ]\n",
    "}\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Output from node '{key}':\")\n",
    "        pprint(\"---\")\n",
    "        pprint(value, indent=2, width=120, depth=None)\n",
    "    pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0fb7a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALLING AGENT---\n",
      "\"Output from node 'agent':\"\n",
      "'---'\n",
      "{ 'messages': [ AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'mistral', 'created_at': '2025-05-07T13:52:08.0640251Z', 'done': True, 'done_reason': 'stop', 'total_duration': 437467100, 'load_duration': 6141200, 'prompt_eval_count': 89, 'prompt_eval_duration': 6640400, 'eval_count': 26, 'eval_duration': 423603300, 'model_name': 'mistral'}, id='run--6e30b3b5-a10e-4a2b-8b72-afa1df2152cd-0', tool_calls=[{'name': 'retriever_tool', 'args': {'query': 'MGI Digital Technology Headquarters Address'}, 'id': '4ab9d0a3-4b0a-4577-a1ab-84a636b8ce05', 'type': 'tool_call'}], usage_metadata={'input_tokens': 89, 'output_tokens': 26, 'total_tokens': 115})]}\n",
      "'\\n---\\n'\n",
      "---DOCUMENTS RELEVANT---\n",
      "\"Output from node 'retrieve':\"\n",
      "'---'\n",
      "{ 'messages': [ ToolMessage(content='AccurioShine 3600  \\n \\nUser Manual - 2 - \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nCreated by MGI Digital Technology  \\n4, rue de la Méridienne \\n94260 Fresnes \\nFRANCE \\n \\nIf you have any comments or suggestions about this manual, feel free to report them to your local SSD \\norganization (Technical Support), which will forward them to MGI. Thank you! \\n  \\nCopyright © 2006-2025 MGI S.A. All rights reserved. \\n \\nThe copyright protection includes all forms of material content and information subject to all applicable legal \\nstandards of government regulations and relevant laws of judicial court protection. This includes without \\nexception the contents generated by software and displayed on the screen such as format, patterns, symbols, \\nscreen display, layout. \\n \\nMGI®, the MGI logo and all MGI products mentioned in this document are trademarks of MGI Digital Technology, \\nin France (FR) and/or other countries. AccurioShine is a trademark of Konica Minolta Inc. All brand names and \\nproducts mentioned are trademarks of their respective holders and are hereby acknowledged. \\n \\nThis document is not a contractual document and technical specifications are subject to change without notice. \\n \\nConfidential - document strictly reserved to authorized persons by MGI Digital Technology\\n\\nUser Manual - 7 - \\n \\nAccurioShine 3600  \\n1 REVISION HISTORY \\nThe following changes have been made from the original version. \\n \\nVersion Date Comments \\nVersion 1.0 28/01/2022 Initial release \\nVersion 1.1 11/02/2022 iFOIL One compatibility added \\nVersion 1.2 21/02/2022 New LED error status added when the Hoya LED Type 2 is wired  \\nVersion 1.3 15/03/2022 UK Declaration of Conformity certificates (Printer + Universal Feeder) \\nVersion 1.4 16/05/2022 Optional iFOIL One module described \\nOptional CTS S Corona module described \\nVersion 1.5 08/06/2022 Warning added about Workstation mouse cleaning after printhead \\ncleaning \\nVersion 1.6 17/01/2023 Front page logo changed \\n4 error messages from orange to red status \\nVersion 1.7 12/05/2023 EC certificates changed - Batch #1 & batch #2 introduced \\nVersion 1.8 22/05/2023 New instructions about the MGI LED Flashlights – see page 22 \\nVersion 1.9 02/06/2023 Special substrates remarks added – see page 25 \\nVersion 2.0 20/09/2023 New MGI flashlight shipped with the equipment – new instructions how \\nto use it – see pages 22-23 \\nVersion 2.1 23/10/2024 EC & UK Certificates updated – Batch #3 introduced \\nVersion 2.2 13/03/2025 Important recommendation added - sticky substrates & Substrate \\nthickness \\n   \\n \\nThis manual covers the features of the equipment produced by MGI, from September 2023. \\n \\n \\nREMARK ABOUT THE COVER COLORS \\nThe colors of the equipment cover (grey and blue) used in the manual  \\ndoes not always match the colors of the covers of your own equipment.  \\n \\nThis does not change at all the quality and accuracy of these operating instructions.\\n\\nAccurioShine 3600 \\n \\n \\n \\nUser Manual - 24 - \\n \\nTo avoid a varnish polymerization generated by a MGI LED flashlight, we are giving you the maximum \\nexposure timing and distances to respect . Any polymerization damage occurred by a not authorized \\nusage, will not be covered by the manufacturer or the Service Contract. \\n \\n \\n• MGI LED Flashlight V1 \\nVarnish Types MGI LED Flashlight V1 \\nMGI 3D varnish families  \\n(LED & UV) \\n \\nDIRECT EXPOSURE (worst case) \\nMax. 1 min. at 20 cm away from the PrintHeads \\n \\n• MGI LED Flashlight V2 \\nVarnish Types MGI LED Flashlight V2 \\nMGI 3D varnish families  \\n(LED & UV) \\nALWAYS use the 50% power position on the \\nFlashlight  \\n(Press once the ON/OFF button) \\n \\nDIRECT EXPOSURE (worst case) \\nMax. 8 min. at 20 cm away from the PrintHeads \\n \\n• MGI LED Flashlight V3 \\nVarnish Types MGI LED Flashlight V3 \\nMGI 3D varnish families  \\n(LED & UV) \\nALWAYS use the yellow color position on the \\nFlashlight  \\n(yellow = warm color) \\n \\n(Press TWICE the ON/OFF button). If you keep depressed \\nthis button, the light intensity is progressively reduced. \\n \\nDIRECT EXPOSURE (worst case) \\nMax. 8 min. at 20 cm away from the PrintHeads \\n \\nDO NOT USE THE FRONT LIGHT (activated by the \\n2nd smaller ON/OFF button) \\nReminder \\nTo order the authorized MGI Flashlight, use the PN 5254 (currently, the \\nMGI Flashlight V3 from mid-2023).\\n\\nAccurioShine 3600 \\n \\n \\n \\nUser Manual - 23 - \\n \\n3.11 LED Flashlights used nearby the UV Printheads \\nWhen the Operator needs to perform some maintenance operations inside the UV Print Engine, it might \\nbe convenient to use a Flashlight to better see inside this cabinet. \\n \\nThe MGI LED flashlights are the only authorized light sources to avoid any polymerization problem within \\nthe Printheads and/or the Varnish circuits. Any other lights are prohibited (Smartphone, Maglite, …). \\n \\nMGI delivered several Flashlight models over time: \\n \\n• Original LED Flashlight (V1) delivered until June 2022 (see picture #1). \\n \\n \\nPicture #1 – MGI LED Flashlight V1 \\n \\n \\n \\n• From September 2022, MGI changed to another LED Flashlight (see picture #2). \\n \\n \\nPicture #2 – MGI LED Flashlight V2 \\n \\n \\n \\n \\n• From mid-2023, due to a sourcing issue, MGI changed to this LED Flashlight (see picture #3). \\n \\n \\nPicture #3 – MGI LED Flashlight V3 \\n \\n \\nMGI is continuously modifying the varnish formulas to comply with stricter environmental regulations and \\nto improve overall varnish performances. These chemical changes introduced a greater sensitivity to the \\nUV radiations. After recent tests, MGI Chemical Department demonstrated the MGI LED Flashlights could \\nemit enough UV radiations to have an impact on the varnish polymerization.  \\n  \\nON/OFF button \\nON/OFF button', name='retriever_tool', id='ed761560-488f-41ab-b4d8-e033c38f9595', tool_call_id='4ab9d0a3-4b0a-4577-a1ab-84a636b8ce05')]}\n",
      "'\\n---\\n'\n",
      "---GENERATING RESPONSE---\n",
      "\"Output from node 'generate':\"\n",
      "'---'\n",
      "{ 'messages': [ ' The address of MGI headquarters is located at 4, rue de la Méridienne, 94260 Fresnes, FRANCE. This '\n",
      "                'information was found on page 2 of the User Manual for AccurioShine 3600.']}\n",
      "'\\n---\\n'\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"What is the adress of MGI headquarters?\"),\n",
    "    ]\n",
    "}\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Output from node '{key}':\")\n",
    "        pprint(\"---\")\n",
    "        pprint(value, indent=2, width=120, depth=None)\n",
    "    pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "414fe0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction encapsule les appels au graphe\n",
    "\n",
    "def ask_ai(message):\n",
    "    if(type(message) != str):\n",
    "        raise TypeError(\"Message must be a string\")    \n",
    "    \n",
    "    inputs = { \"messages\": [(\"user\", message)]}\n",
    "    \n",
    "    graph = workflow.compile()\n",
    "\n",
    "    for output in graph.stream(inputs):\n",
    "        # print(output)\n",
    "        pass\n",
    "        # for key, value in output.items():\n",
    "        #     # print(f\"Output from node '{key}':\")\n",
    "        #     # pprint(value, indent=2, width=110, depth=None)\n",
    "    \n",
    "    try:\n",
    "        result = output[\"agent\"][\"messages\"][0]\n",
    "    except:\n",
    "        result = output[\"generate\"][\"messages\"][0]\n",
    "\n",
    "    return result            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f6453c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALLING AGENT---\n",
      "---DOCUMENTS RELEVANT---\n",
      "---GENERATING RESPONSE---\n",
      "\n",
      "\n",
      "---RESULTAT FINAL---\n",
      "(' The address of MGI headquarters is located at 4, rue de la Méridienne, '\n",
      " '94260 Fresnes, FRANCE. (Source: User Manual - 2)')\n"
     ]
    }
   ],
   "source": [
    "res = ask_ai(\"What is the adress of MGI headquarters?\")  # Appel à l'agent\n",
    "\n",
    "print(\"\\n\\n---RESULTAT FINAL---\")\n",
    "pprint(res, indent=2, width=80, depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluator(state):\n",
    "#     print(\"---EVALUATION---\")\n",
    "#     messages = state[\"messages\"]\n",
    "#     question = messages[0].content\n",
    "#     last_message = messages[-1].content\n",
    "#     print(\"Question: {question}\")\n",
    "#     print(\"Answer: {last_message}\")\n",
    "\n",
    "#     return {\"messages\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c57d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cette fonction évalue la réponse de l'agent\n",
    "\n",
    "# # Elle prend en entrée la question, la réponse correcte et la réponse de l'agent\n",
    "# # Elle renvoie un score compris entre 0 et 1  \n",
    "\n",
    "# def fact_check(question, correct_answer, agent_answer):\n",
    "#     prompt = f\"\"\"You are a teacher grading a quiz. \n",
    "# You will be given a QUESTION, the GROUND TRUTH (correct) ANSWER, and the STUDENT ANSWER. \n",
    "# Here is the grade criteria to follow:\n",
    "# (1) Grade the student answers based ONLY on their factual accuracy relative to the ground truth answer. \n",
    "# (2) Ensure that the student answer does not contain any conflicting statements.\n",
    "# (3) It is OK if the student answer contains more information than the ground truth answer, as long as it is factually accurate relative to the  ground truth answer.\n",
    "# Score:\n",
    "# A score of 1 means that the student's answer meets all of the criteria. This is the highest (best) score. \n",
    "# A score of 0 means that the student's answer does not meet all of the criteria. This is the lowest possible score you can give.\n",
    "# The score should be a float between 0 and 1, inclusive.\n",
    "# You must only give the score.\n",
    "# ---\n",
    "# QUESTION:\n",
    "# {question}\n",
    "# ---\n",
    "# GROUND TRUTH ANSWER: \n",
    "# {correct_answer}\n",
    "# ---\n",
    "# STUDENT ANSWER: \n",
    "# {agent_answer}\n",
    "# ---\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "#     model = ChatmistralAI(temperature=0, streaming=True, model=model)\n",
    "    \n",
    "#     response = model.invoke(prompt)\n",
    "#     return (float)(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f52f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fact_check(\"Est-ce que ça va ?\", \"Oui, ça va.\", \"Non, ça ne va pas.\")) # 0.0\n",
    "# print(fact_check(\"Est-ce que ça va ?\", \"Oui, ça va.\", \"Oui, ça va.\")) # 1.0\n",
    "\n",
    "# print(fact_check(\"Quelle est la date de la révolution française ?\", \"mardi 14 juillet 1789\", \"1789\")) # 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d40ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
